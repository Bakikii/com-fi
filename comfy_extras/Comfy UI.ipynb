{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"gF1S6DImECxb"},"outputs":[],"source":["import re\n","from IPython.utils import io\n","clone_comfy_ui = True #@param {type:\"boolean\"}\n","\n","if clone_comfy_ui:\n","  with io.capture_output() as captured:\n","    !git clone https://github.com/Silversith/ComfyUI\n","    %cd ComfyUI\n","    !pip install xformers -r requirements.txt\n","\n","    !wget http://launchpadlibrarian.net/367274644/libgoogle-perftools-dev_2.5-2.2ubuntu3_amd64.deb\n","    !apt-get -y install -qq aria2\n","\n","  output_text = captured.stdout\n","\n","  # Use regex to find URLs in the captured output\n","  errors = re.findall(r'(?i)err(or)?.*', output_text)\n","\n","  # Display each URL as a clickable link\n","  for error in errors:\n","      print(error)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"yfhr6Kry5nus"},"outputs":[],"source":["import re\n","from IPython.utils import io\n","custom_nodes = False #@param {type:\"boolean\"}\n","WAS_node_suite = True #@param {type:\"boolean\"}\n","\n","if custom_nodes:\n","  with io.capture_output() as captured:\n","    %cd custom_nodes # Start getting the latest updates from Github for the extensions.\n","    !git clone https://github.com/lilly1987/ComfyUI_node_Lilly.git\n","    %cd ComfyUI_node_Lilly\n","    !git pull\n","    %cd ../\n","    !git clone https://github.com/Derfuu/Derfuu_ComfyUI_ModdedNodes.git\n","    %cd Derfuu_ComfyUI_ModdedNodes\n","    !git pull\n","    %cd ../\n","    !git clone https://github.com/WASasquatch/was-node-suite-comfyui.git\n","    %cd was-node-suite-comfyui\n","    !git pull\n","    %cd ../\n","    !git clone https://github.com/pythongosssss/ComfyUI-Custom-Scripts.git\n","    %cd ComfyUI-Custom-Scripts\n","    !git pull\n","    %cd ../\n","    !git clone https://github.com/Fannovel16/FN16-ComfyUI-nodes.git\n","    %cd FN16-ComfyUI-nodes\n","    !git pull\n","    %cd ../\n","    !git clone https://github.com/omar92/ComfyUI-extra-nodes---quality-of-life.git\n","    %cd ComfyUI-extra-nodes---quality-of-life\n","    !git pull\n","    %cd ../\n","    !git clone https://github.com/guoyk93/yk-node-suite-comfyui.git\n","    %cd yk-node-suite-comfyui\n","    !git pull\n","    %cd ../\n","    !git clone https://github.com/gamert/ComfyUI_tagger.git\n","    %cd ComfyUI_tagger\n","    !git pull\n","    %cd ../\n","    !git clone https://github.com/m957ymj75urz/ComfyUI-Custom-Nodes.git\n","    %cd ComfyUI-Custom-Nodes\n","    !git pull\n","    %cd ../\n","    !git clone https://github.com/Davemane42/ComfyUI_Dave_CustomNode.git\n","    %cd ComfyUI_Dave_CustomNode\n","    !git pull\n","    %cd ../\n","\n","    %cd ../web/extensions\n","    !git clone https://github.com/diffus3/ComfyUI-extensions ./web/extensions/diffus3\n","\n","    %cd ../../script_examples\n","    !git clone https://github.com/lilly1987/ComfyUI-script.git\n","    !git clone https://github.com/lilly1987/ComfyUI_script2.git\n","\n","\n","if WAS_node_suite:\n","  with io.capture_output() as captured:\n","    !git -C /content/ComfyUI/custom_nodes clone https://github.com/WASasquatch/was-node-suite-comfyui/ \n","\n","output_text = captured.stdout\n","\n","# Use regex to find URLs in the captured output\n","errors = re.findall(r'(?i)err(or)?.*', output_text)\n","\n","# Display each URL as a clickable link\n","for error in errors:\n","    print(error)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","executionInfo":{"elapsed":450818,"status":"ok","timestamp":1680708380963,"user":{"displayName":"J van der Gryp","userId":"02305628043780299530"},"user_tz":-120},"id":"SktLkvOS-lzN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"95e97e5c-598f-4c02-c58f-7ab772fdcdd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["OR\n"]}],"source":["import re\n","from IPython.utils import io\n","# SD2_1_models = True #@param {type:\"boolean\"}\n","controlnet_models = True #@param {type:\"boolean\"}\n","download_models = True #@param {type:\"boolean\"}\n","download_vae = True #@param {type:\"boolean\"}\n","download_negative_embed = True #@param {type:\"boolean\"}\n","download_loras = True #@param {type:\"boolean\"}\n","\n","# if SD2_1_models:\n","#   with io.capture_output() as captured:\n","#     #SD 2.1\n","#     !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M 'https://civitai.com/api/download/models/20491?type=Model&format=SafeTensor' -d ./models/checkpoints/ -o realismEngineMeet_v10.safetensors\n","#     !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M 'https://civitai.com/api/download/models/20414?type=Config&format=Other' -d ./models/configs -o realismEngineMeet_v10.yaml\n","#     !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M 'https://civitai.com/api/download/models/29221?type=Pruned%20Model&format=SafeTensor' -d ./models/checkpoints/ -o hubbahubba_v10.safetensors\n","  \n","#   output_text = captured.stdout\n","\n","#   # Use regex to find URLs in the captured output\n","#   errors = re.findall(r'(?i)err(or)?.*', output_text)\n","\n","#   # Display each URL as a clickable link\n","#   for error in errors:\n","#       print(error)\n","\n","if controlnet_models:\n","  with io.capture_output() as captured:\n","    !wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n","    # !wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n","    # !wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n","    # !wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n","    # !wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n","    # !wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n","    # !wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n","\n","    !wget -c https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_depth-fp16.safetensors -P ./models/controlnet/\n","    # !wget -c https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_scribble-fp16.safetensors -P ./models/controlnet/\n","    # !wget -c https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_openpose-fp16.safetensors -P ./models/controlnet/\n","    !wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n","    !cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n","    \n","  output_text = captured.stdout\n","\n","  # Use regex to find URLs in the captured output\n","  errors = re.findall(r'(?i)err(or)?.*', output_text)\n","\n","  # Display each URL as a clickable link\n","  for error in errors:\n","      print(error)\n","\n","if download_models:\n","  with io.capture_output() as captured:\n","    # Checkpoints\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k  1M 'https://civitai.com/api/download/models/5636?type=Model&format=SafeTensor' -d ./models/checkpoints/ -o dreamshaper_331BakedVae.safetensors\n","    #!aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M 'https://civitai.com/api/download/models/19575?type=Model&format=SafeTensor' -d ./models/checkpoints/ -o revAnimated_v11.safetensors\n","    #!wget -c https://huggingface.co/SakerLy/chilloutmix_NiPrunedFp32Fix/resolve/main/chilloutmix_NiPrunedFp32Fix.safetensors -P ./models/checkpoints/ -nc\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M 'https://civitai.com/api/download/models/21758' -d ./models/checkpoints/ -o meowMixRealistic_prunedFp16FIXED.safetensors\n","    #!aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M 'https://civitai.com/api/download/models/6737' -d ./models/checkpoints/ -o zxtcsAnime_v10.ckpt\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M 'https://civitai.com/api/download/models/11925?type=Pruned%20Model&format=SafeTensor' -d ./models/checkpoints/ -o neverendingDreamNED_bakedVae.safetensors\n","\n","if download_vae:\n","  with io.capture_output() as captured:\n","    # VAE\n","    !wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n","    #!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n","    #!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n","\n","if download_negative_embed:\n","  with io.capture_output() as captured:\n","    #Embeddings\n","    !wget -c https://huggingface.co/datasets/Nerfgun3/bad_prompt/resolve/main/bad_prompt_version2.pt -P ./models/embeddings\n","    !wget -c https://huggingface.co/yesyeahvh/bad-hands-5/resolve/main/bad-hands-5.pt -P ./models/embeddings\n","\n","if download_loras:\n","  with io.capture_output() as captured:\n","    # Loras\n","    !pip install --upgrade --no-cache-dir gdown\n","    !gdown 1MQBNdwqgTJCFa5wOg6FBq0-Hc9z-sGvH -O ./models/loras/ShinyEyesStyle.safetensors\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/12504 -d ./models/loras -o oversizedShirt_v10.safetensors\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/12873 -d ./models/loras -o inniesBetterVaginas_v11.safetensors\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/11979 -d ./models/loras -o negligee_v10.safetensors\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/10490 -d ./models/loras -o gin00pussy_.safetensors\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/8527 -d ./models/loras -o charturnerbetaLora_charturnbetalora.safetensors\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M 'https://civitai.com/api/download/models/16576?type=Model&format=SafeTensor' -d ./models/loras -o epiNoiseoffset_v2.safetensors\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M 'https://civitai.com/api/download/models/18445?type=Model&format=SafeTensor' -d ./models/loras -o epiNoiseoffset_v2Pynoise.safetensors\n","    #!aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/16907 -d ./models/loras -o fixhand2lora_v10.safetensors\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/20974 -d ./models/loras -o poseFixingHelper_posev4.safetensors\n","    !aria2c --conditional-get --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/30420 -d ./models/loras -o realSpreadPussy_sppSpreadpussyWV1.safetensors\n","\n","    # ESRGAN upscale model\n","    !wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n","    !wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n","    !wget -c https://huggingface.co/WuLing/SD-WebUI-TW/resolve/main/ESRGAN/4x-UltraSharp.pth -P ./models/upscale_models/\n","  \n","\n","  output_text = captured.stdout\n","\n","  # Use regex to find URLs in the captured output\n","  errors = re.findall(r'(?i)err(or)?.*', output_text)\n","\n","  # Display each URL as a clickable link\n","  for error in errors:\n","      print(error)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Xq3MHlKwpdsN"},"outputs":[],"source":["import re\n","run_elFinder = False #@param {type:\"boolean\"}\n","if run_elFinder:\n","  %store -r\n","  !pip -q install --upgrade gallery-dl gdown imjoy-elfinder\n","\n","  import threading\n","  from google.colab import output\n","  from imjoy_elfinder.app import main\n","  thread = threading.Thread(target=main, args=[[\"--root-dir=/content\", \"--port=8765\", \"--thumbnail\"]])\n","  thread.start()\n","  output.serve_kernel_port_as_window(8765)\n","  \n","output_text = captured.stdout\n","\n","# Use regex to find URLs in the captured output\n","errors = re.findall(r'(?i)err(or)?.*', output_text)\n","\n","# Display each URL as a clickable link\n","for error in errors:\n","    print(error)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","executionInfo":{"elapsed":6577,"status":"ok","timestamp":1680718871115,"user":{"displayName":"J van der Gryp","userId":"02305628043780299530"},"user_tz":-120},"id":"fD6Cmdp1Pf8X","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa88e116-c799-48ba-cc0a-ff89aa0157fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["https://coaches-li-capacity-heads.trycloudflare.com\n"]}],"source":["from IPython.utils import io\n","import re\n","\n","start_cloudflared_tunnel = True #@param {type:\"boolean\"}\n","if start_cloudflared_tunnel:\n","  with io.capture_output() as captured:\n","    !wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared-linux-amd64 && chmod 777 /content/cloudflared-linux-amd64\n","    import atexit, requests, subprocess, time, re, os\n","    from random import randint\n","    from threading import Timer\n","    from queue import Queue\n","    def cloudflared(port, metrics_port, output_queue):\n","        atexit.register(lambda p: p.terminate(), subprocess.Popen(['/content/cloudflared-linux-amd64', 'tunnel', '--url', f'http://127.0.0.1:{port}', '--metrics', f'127.0.0.1:{metrics_port}'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT))\n","        attempts, tunnel_url = 0, None\n","        while attempts < 10 and not tunnel_url:\n","            attempts += 1\n","            time.sleep(3)\n","            try:\n","                tunnel_url = re.search(\"(?P<url>https?:\\/\\/[^\\s]+.trycloudflare.com)\", requests.get(f'http://127.0.0.1:{metrics_port}/metrics').text).group(\"url\")\n","            except:\n","                pass\n","        if not tunnel_url:\n","            raise Exception(\"Can't connect to Cloudflare Edge\")\n","        output_queue.put(tunnel_url)\n","    output_queue, metrics_port = Queue(), randint(8100, 9000)\n","    thread = Timer(2, cloudflared, args=(8188, metrics_port, output_queue))\n","    thread.start()\n","    thread.join()\n","    tunnel_url = output_queue.get()\n","    os.environ['webui_url'] = tunnel_url\n","    print(tunnel_url)\n","\n","output_text = captured.stdout\n","\n","# Use regex to find URLs in the captured output\n","urls = re.findall(r'(?P<url>https?:\\/\\/[^\\s]+.trycloudflare.com)', output_text)\n","\n","# Display each URL as a clickable link\n","for url in urls:\n","    print(url)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"la6-KZRupgtJ","outputId":"133d1402-1d25-4de4-90eb-571ce020b471"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n","+ localtunnel@2.0.2\n","updated 1 package in 1.263s\n","\n","\u001b[33m\u001b[39m\n","\u001b[33m   ╭───────────────────────────────────────────────────────────────╮\u001b[39m\n","   \u001b[33m│\u001b[39m                                                               \u001b[33m│\u001b[39m\n","   \u001b[33m│\u001b[39m      New \u001b[31mmajor\u001b[39m version of npm available! \u001b[31m6.14.8\u001b[39m → \u001b[32m9.6.3\u001b[39m       \u001b[33m│\u001b[39m\n","   \u001b[33m│\u001b[39m   \u001b[33mChangelog:\u001b[39m \u001b[36mhttps://github.com/npm/cli/releases/tag/v9.6.3\u001b[39m   \u001b[33m│\u001b[39m\n","   \u001b[33m│\u001b[39m               Run \u001b[32mnpm install -g npm\u001b[39m to update!               \u001b[33m│\u001b[39m\n","   \u001b[33m│\u001b[39m                                                               \u001b[33m│\u001b[39m\n","\u001b[33m   ╰───────────────────────────────────────────────────────────────╯\u001b[39m\n","\u001b[33m\u001b[39m\n","Enabling highvram mode because your GPU has more vram than your computer has ram. If you don't want this use: --normalvram\n","Set vram state to: HIGH VRAM\n","2023-04-05 18:21:26.347046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Using xformers cross attention\n","\u001b[34mWAS Node Suite:\u001b[0m Running At: /content/ComfyUI/custom_nodes/was-node-suite-comfyui/WAS_Node_Suite.py\n","\u001b[34mWAS Node Suite:\u001b[0m Running From: /content/ComfyUI/custom_nodes/was-node-suite-comfyui\n","\u001b[34mWAS Node Suite: \u001b[92mLoaded\u001b[0m\n","\n","ComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\n","your url is: https://whole-ants-turn-34-83-154-206.loca.lt\n","got prompt\n","/usr/local/lib/python3.9/dist-packages/safetensors/torch.py:99: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  with safe_open(filename, framework=\"pt\", device=device) as f:\n","/usr/local/lib/python3.9/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","/usr/local/lib/python3.9/dist-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = cls(wrap_storage=untyped_storage)\n","got prompt\n","got prompt\n","got prompt\n","got prompt\n","making attention of type 'vanilla-xformers' with 512 in_channels\n","building MemoryEfficientAttnBlock with 512 in_channels...\n","Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n","making attention of type 'vanilla-xformers' with 512 in_channels\n","building MemoryEfficientAttnBlock with 512 in_channels...\n","got prompt\n","got prompt\n","got prompt\n","LatentDiffusion: Running in eps-prediction mode\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","got prompt\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","got prompt\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","DiffusionWrapper has 859.52 M params.\n"," 64% 16/25 [00:18<00:07,  1.19it/s]got prompt\n"," 72% 18/25 [00:20<00:05,  1.20it/s]got prompt\n"," 84% 21/25 [00:22<00:03,  1.19it/s]got prompt\n"," 96% 24/25 [00:25<00:00,  1.19it/s]got prompt\n","100% 25/25 [00:26<00:00,  1.05s/it]\n","making attention of type 'vanilla-xformers' with 512 in_channels\n","building MemoryEfficientAttnBlock with 512 in_channels...\n","Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n","making attention of type 'vanilla-xformers' with 512 in_channels\n","building MemoryEfficientAttnBlock with 512 in_channels...\n","Restored from /content/ComfyUI/models/vae/vae-ft-mse-840000-ema-pruned.safetensors\n","got prompt\n","got prompt\n","got prompt\n","got prompt\n","making attention of type 'vanilla-xformers' with 512 in_channels\n","building MemoryEfficientAttnBlock with 512 in_channels...\n","Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n","making attention of type 'vanilla-xformers' with 512 in_channels\n","building MemoryEfficientAttnBlock with 512 in_channels...\n","got prompt\n","LatentDiffusion: Running in eps-prediction mode\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","got prompt\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","DiffusionWrapper has 859.52 M params.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n","100% 25/25 [02:08<00:00,  5.13s/it]\n","100% 25/25 [00:21<00:00,  1.18it/s]\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n","100% 25/25 [02:08<00:00,  5.13s/it]\n","100% 25/25 [00:21<00:00,  1.18it/s]\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n","100% 25/25 [02:08<00:00,  5.13s/it]\n","100% 25/25 [00:21<00:00,  1.18it/s]\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n"," 96% 24/25 [02:02<00:05,  5.11s/it]got prompt\n","got prompt\n","100% 25/25 [02:07<00:00,  5.12s/it]\n","got prompt\n","got prompt\n","got prompt\n","got prompt\n","got prompt\n","  8% 2/25 [00:01<00:20,  1.15it/s]got prompt\n"," 40% 10/25 [00:08<00:12,  1.19it/s]got prompt\n"," 60% 15/25 [00:12<00:08,  1.18it/s]got prompt\n","100% 25/25 [00:21<00:00,  1.19it/s]\n","got prompt\n","got prompt\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n","  4% 1/25 [00:04<01:37,  4.07s/it]got prompt\n"," 12% 3/25 [00:15<01:55,  5.27s/it]got prompt\n"," 16% 4/25 [00:20<01:49,  5.23s/it]got prompt\n","got prompt\n"," 20% 5/25 [00:25<01:44,  5.21s/it]got prompt\n"," 24% 6/25 [00:30<01:38,  5.18s/it]got prompt\n"," 28% 7/25 [00:36<01:32,  5.16s/it]got prompt\n"," 28% 7/25 [00:40<01:42,  5.72s/it]\n","Traceback (most recent call last):\n","  File \"/content/ComfyUI/execution.py\", line 182, in execute\n","    executed += recursive_execute(self.server, prompt, self.outputs, x, extra_data)\n","  File \"/content/ComfyUI/execution.py\", line 58, in recursive_execute\n","    executed += recursive_execute(server, prompt, outputs, input_unique_id, extra_data)\n","  File \"/content/ComfyUI/execution.py\", line 58, in recursive_execute\n","    executed += recursive_execute(server, prompt, outputs, input_unique_id, extra_data)\n","  File \"/content/ComfyUI/execution.py\", line 67, in recursive_execute\n","    outputs[unique_id] = getattr(obj, obj.FUNCTION)(**input_data_all)\n","  File \"/content/ComfyUI/nodes.py\", line 685, in sample\n","    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n","  File \"/content/ComfyUI/nodes.py\", line 654, in common_ksampler\n","    samples = sampler.sample(noise, positive_copy, negative_copy, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask)\n","  File \"/content/ComfyUI/comfy/samplers.py\", line 489, in sample\n","    samples = getattr(k_diffusion_sampling, \"sample_{}\".format(self.sampler))(self.model_k, noise, sigmas, extra_args=extra_args)\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 594, in sample_dpmpp_2m\n","    denoised = model(x, sigmas[i] * s_in, **extra_args)\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/ComfyUI/comfy/samplers.py\", line 225, in forward\n","    out = self.inner_model(x, sigma, cond=cond, uncond=uncond, cond_scale=cond_scale, cond_concat=cond_concat)\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/ComfyUI/comfy/k_diffusion/external.py\", line 114, in forward\n","    eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n","  File \"/content/ComfyUI/comfy/k_diffusion/external.py\", line 140, in get_eps\n","    return self.inner_model.apply_model(*args, **kwargs)\n","  File \"/content/ComfyUI/comfy/samplers.py\", line 213, in apply_model\n","    out = sampling_function(self.inner_model.apply_model, x, timestep, uncond, cond, cond_scale, cond_concat)\n","  File \"/content/ComfyUI/comfy/samplers.py\", line 195, in sampling_function\n","    cond, uncond = calc_cond_uncond_batch(model_function, cond, uncond, x, timestep, max_total_area, cond_concat)\n","  File \"/content/ComfyUI/comfy/samplers.py\", line 175, in calc_cond_uncond_batch\n","    model_management.throw_exception_if_processing_interrupted()\n","  File \"/content/ComfyUI/comfy/model_management.py\", line 293, in throw_exception_if_processing_interrupted\n","    raise InterruptProcessingException()\n","model_management.InterruptProcessingException\n","\n","got prompt\n","making attention of type 'vanilla-xformers' with 512 in_channels\n","building MemoryEfficientAttnBlock with 512 in_channels...\n","Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n","making attention of type 'vanilla-xformers' with 512 in_channels\n","building MemoryEfficientAttnBlock with 512 in_channels...\n","LatentDiffusion: Running in eps-prediction mode\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","DiffusionWrapper has 859.52 M params.\n","100% 25/25 [00:21<00:00,  1.19it/s]\n","making attention of type 'vanilla-xformers' with 512 in_channels\n","building MemoryEfficientAttnBlock with 512 in_channels...\n","Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n","making attention of type 'vanilla-xformers' with 512 in_channels\n","building MemoryEfficientAttnBlock with 512 in_channels...\n","LatentDiffusion: Running in eps-prediction mode\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n","Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n","DiffusionWrapper has 859.52 M params.\n","got prompt\n","got prompt\n","got prompt\n","got prompt\n","torch.Size([2, 3, 1280, 1280])\n","got prompt\n","got prompt\n","got prompt\n","  0% 0/25 [00:00<?, ?it/s]2 2\n","got prompt\n","  8% 2/25 [00:10<02:03,  5.35s/it]got prompt\n"," 12% 3/25 [00:15<01:55,  5.25s/it]got prompt\n","100% 25/25 [02:08<00:00,  5.13s/it]\n","100% 25/25 [00:21<00:00,  1.19it/s]\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n","100% 25/25 [02:08<00:00,  5.12s/it]\n","100% 25/25 [00:21<00:00,  1.18it/s]\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n","100% 25/25 [02:08<00:00,  5.12s/it]\n","100% 25/25 [00:21<00:00,  1.18it/s]\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n","100% 25/25 [02:08<00:00,  5.12s/it]\n","100% 25/25 [00:21<00:00,  1.18it/s]\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n","100% 25/25 [02:07<00:00,  5.11s/it]\n","100% 25/25 [00:21<00:00,  1.18it/s]\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n","100% 25/25 [02:07<00:00,  5.11s/it]\n","100% 25/25 [00:21<00:00,  1.19it/s]\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n","100% 25/25 [02:07<00:00,  5.11s/it]\n","100% 25/25 [00:21<00:00,  1.19it/s]\n","torch.Size([2, 3, 1280, 1280])\n","  0% 0/25 [00:00<?, ?it/s]2 2\n"," 88% 22/25 [01:52<00:15,  5.11s/it]"]}],"source":["import subprocess\n","import threading\n","import time\n","import socket\n","from IPython.utils import io\n","\n","start_local_tunnel = True #@param {type:\"boolean\"}\n","if start_local_tunnel:\n","  \n","  !npm install -g localtunnel\n","\n","  def capture_output(cmd):\n","    \"\"\"Capture the output of a command as it's running.\"\"\"\n","    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","    while True:\n","        line = proc.stdout.readline().decode().strip()\n","        if not line:\n","            break\n","        yield line\n","\n","  with io.capture_output() as captured:\n","    def iframe_thread(port):\n","      while True:\n","          time.sleep(0.5)\n","          sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n","          result = sock.connect_ex(('127.0.0.1', port))\n","          if result == 0:\n","            break\n","          sock.close()\n","      print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\")\n","      p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n","      for line in p.stdout:\n","        print(line.decode(), end='')\n","\n","    threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n","  !python main.py --dont-print-server"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1Qk6OATak14Hv3MLdJRh7_aANKbXXgi4Z","timestamp":1678998068703}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}